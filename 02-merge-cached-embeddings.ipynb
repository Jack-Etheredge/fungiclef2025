{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "formatted"
    ]
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import os\n",
    "import json\n",
    "import yaml\n",
    "from pathlib import Path\n",
    "from types import SimpleNamespace\n",
    "import argparse\n",
    "\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from torchvision import transforms as tfms\n",
    "import torchvision.transforms as T\n",
    "\n",
    "from typing import Sequence, Tuple, Any, Dict, List, Optional, Union\n",
    "import importlib\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.metrics import top_k_accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "formatted"
    ]
   },
   "outputs": [],
   "source": [
    "# path to fungitatsic dataset\n",
    "data_path = Path('~/datasets/fungiclef2025/').expanduser().resolve()\n",
    "# data_path = '/kaggle/input/fungi-clef-2025/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "formatted"
    ]
   },
   "outputs": [],
   "source": [
    "class FungiTastic(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    Dataset class for the FewShot subset of the Danish Fungi dataset (size 300, closed-set).\n",
    "\n",
    "    This dataset loader supports training, validation, and testing splits, and provides\n",
    "    convenient access to images, class IDs, and file paths. It also supports optional\n",
    "    image transformations.\n",
    "    \"\"\"\n",
    "\n",
    "    SPLIT2STR = {'train': 'Train', 'val': 'Val', 'test': 'Test'}\n",
    "\n",
    "    def __init__(self, root: str, split: str = 'val', transform=None):\n",
    "        \"\"\"\n",
    "        Initializes the FungiTastic dataset.\n",
    "\n",
    "        Args:\n",
    "            root (str): The root directory of the dataset.\n",
    "            split (str, optional): The dataset split to use. Must be one of {'train', 'val', 'test'}.\n",
    "                Defaults to 'val'.\n",
    "            transform (callable, optional): Optional transform to be applied on a sample.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.split = split\n",
    "        self.transform = transform\n",
    "        self.df = self._get_df(root, split)\n",
    "\n",
    "        assert \"image_path\" in self.df\n",
    "        if self.split != 'test':\n",
    "            assert \"category_id\" in self.df\n",
    "            self.n_classes = len(self.df['category_id'].unique())\n",
    "            self.category_id2label = {\n",
    "                k: v[0] for k, v in self.df.groupby('category_id')['species'].unique().to_dict().items()\n",
    "            }\n",
    "            self.label2category_id = {\n",
    "                v: k for k, v in self.category_id2label.items()\n",
    "            }\n",
    "\n",
    "    def add_embeddings(self, embeddings: pd.DataFrame):\n",
    "        \"\"\"\n",
    "        Updates the dataset instance with new embeddings.\n",
    "    \n",
    "        Args:\n",
    "            embeddings (pd.DataFrame): A DataFrame containing 'filename', 'transformation', \n",
    "                                      and 'embedding' columns.\n",
    "        \"\"\"\n",
    "        assert isinstance(embeddings, pd.DataFrame), \"Embeddings must be a pandas DataFrame.\"\n",
    "        assert \"embedding\" in embeddings.columns, \"Embeddings DataFrame must have an 'embedding' column.\"\n",
    "        assert \"transformation\" in embeddings.columns, \"Embeddings DataFrame must have a 'transformation' column.\"\n",
    "        \n",
    "        # Merge on both filename and transformation\n",
    "        self.df = pd.merge(self.df, embeddings, on=[\"filename\"], how=\"left\")\n",
    "        \n",
    "        # Make sure we have embeddings for at least the original images\n",
    "        assert not self.df[self.df[\"transformation\"] == \"original\"][\"embedding\"].isna().any(), \\\n",
    "            \"Missing embeddings for some original images\"\n",
    "\n",
    "    def get_embeddings_for_class(self, id):\n",
    "        # return the embeddings for class class_idx\n",
    "        class_idxs = self.df[self.df['category_id'] == id].index\n",
    "        return self.df.iloc[class_idxs]['embedding']\n",
    "    \n",
    "    @staticmethod\n",
    "    def _get_df(data_path: str, split: str) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Loads the dataset metadata as a pandas DataFrame.\n",
    "\n",
    "        Args:\n",
    "            data_path (str): The root directory where the dataset is stored.\n",
    "            split (str): The dataset split to load. Must be one of {'train', 'val', 'test'}.\n",
    "\n",
    "        Returns:\n",
    "            pd.DataFrame: A DataFrame containing metadata and file paths for the split.\n",
    "        \"\"\"\n",
    "        df_path = os.path.join(\n",
    "            data_path,\n",
    "            \"metadata\",\n",
    "            \"FungiTastic-FewShot\",\n",
    "            f\"FungiTastic-FewShot-{FungiTastic.SPLIT2STR[split]}.csv\"\n",
    "        )\n",
    "        df = pd.read_csv(df_path)\n",
    "        df[\"image_path\"] = df.filename.apply(\n",
    "            lambda x: os.path.join(data_path, \"FungiTastic-FewShot\", split, '500p', x)  # TODO: 300p to fullsize if different embedder that can handle it\n",
    "        )\n",
    "        return df\n",
    "\n",
    "    def __getitem__(self, idx: int):\n",
    "        \"\"\"\n",
    "        Retrieves a single data sample by index.\n",
    "    \n",
    "        Args:\n",
    "            idx (int): Index of the sample to retrieve.\n",
    "            ret_image (bool, optional): Whether to explicitly return the image. Defaults to False.\n",
    "    \n",
    "        Returns:\n",
    "            tuple:\n",
    "                - If embeddings exist: (image?, embedding, category_id, file_path)\n",
    "                - If no embeddings: (image, category_id, file_path) (original version)\n",
    "        \"\"\"\n",
    "        file_path = self.df[\"image_path\"].iloc[idx].replace('FungiTastic-FewShot', 'images/FungiTastic-FewShot')\n",
    "    \n",
    "        if self.split != 'test':\n",
    "            category_id = self.df[\"category_id\"].iloc[idx]\n",
    "        else:\n",
    "            category_id = None\n",
    "\n",
    "        image = Image.open(file_path)\n",
    "    \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "    \n",
    "        # Check if embeddings exist\n",
    "        if \"embedding\" in self.df.columns:\n",
    "            emb = torch.tensor(self.df.iloc[idx]['embedding'], dtype=torch.float32).squeeze()\n",
    "        else:\n",
    "            emb = None  # No embeddings available\n",
    "    \n",
    "\n",
    "        return image, category_id, file_path, emb\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        Returns the number of samples in the dataset.\n",
    "        \"\"\"\n",
    "        return len(self.df)\n",
    "\n",
    "    def get_class_id(self, idx: int) -> int:\n",
    "        \"\"\"\n",
    "        Returns the class ID of a specific sample.\n",
    "        \"\"\"\n",
    "        return self.df[\"category_id\"].iloc[idx]\n",
    "\n",
    "    def show_sample(self, idx: int) -> None:\n",
    "        \"\"\"\n",
    "        Displays a sample image along with its class name and index.\n",
    "        \"\"\"\n",
    "        image, category_id, _, _ = self.__getitem__(idx)\n",
    "        class_name = self.category_id2label[category_id]\n",
    "\n",
    "        plt.imshow(image)\n",
    "        plt.title(f\"Class: {class_name}; id: {idx}\")\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "\n",
    "    def get_category_idxs(self, category_id: int) -> List[int]:\n",
    "        \"\"\"\n",
    "        Retrieves all indexes for a given category ID.\n",
    "        \"\"\"\n",
    "        return self.df[self.df.category_id == category_id].index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Load the datasets\n",
    "\n",
    "train_dataset = FungiTastic(root=data_path, split='train', transform=None)\n",
    "val_dataset = FungiTastic(root=data_path, split='val', transform=None)\n",
    "test_dataset = FungiTastic(root=data_path, split='test', transform=None)\n",
    "\n",
    "# train_dataset.df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_dataset.df.image_path.to_numpy()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_dataset.df.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading, saving, computing embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_name = \"multimodel_cache_fungiclef25\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import json\n",
    "    \n",
    "def save_artifacts(exp_name, train_dataset, val_dataset, test_dataset, config, overwrite=False):\n",
    "    file = Path(f\"numpy_embed_dims_{exp_name}.npy\")\n",
    "    if file.exists() and not overwrite:\n",
    "        raise FileExistsError(\"overwrite is False and artifacts exist.\")\n",
    "    embed_dims = test_dataset.df.emb_dims.iloc[0]\n",
    "    np.save(f\"numpy_embed_dims_{exp_name}.npy\", embed_dims)\n",
    "    train_dataset.df.to_csv(f\"train_df_{exp_name}.csv\", index=None)\n",
    "    val_dataset.df.to_csv(f\"val_df_{exp_name}.csv\", index=None)\n",
    "    test_dataset.df.to_csv(f\"test_df_{exp_name}.csv\", index=None)\n",
    "    np.save(f\"train_numpy_embedding_{exp_name}.npy\", train_dataset.df.embedding.to_numpy())\n",
    "    np.save(f\"val_numpy_embedding_{exp_name}.npy\", val_dataset.df.embedding.to_numpy())\n",
    "    np.save(f\"test_numpy_embedding_{exp_name}.npy\", test_dataset.df.embedding.to_numpy())\n",
    "    with open(f\"config_{exp_name}.json\", \"w\") as f:\n",
    "        json.dump(config, f, sort_keys=True, indent=4)\n",
    "\n",
    "def load_artifacts(exp_name):\n",
    "    train_df = pd.read_csv(f\"train_df_{exp_name}.csv\")\n",
    "    val_df = pd.read_csv(f\"val_df_{exp_name}.csv\")\n",
    "    test_df = pd.read_csv(f\"test_df_{exp_name}.csv\")\n",
    "    embed_dims = np.load(f\"numpy_embed_dims_{exp_name}.npy\", allow_pickle=True)\n",
    "    train_df['embed_dims'] = train_df.apply(lambda row: embed_dims, axis=1)\n",
    "    val_df['embed_dims'] = val_df.apply(lambda row: embed_dims, axis=1)\n",
    "    test_df['embed_dims'] = test_df.apply(lambda row: embed_dims, axis=1)\n",
    "    train_embeddings = np.load(f\"train_numpy_embedding_{exp_name}.npy\", allow_pickle=True)\n",
    "    val_embeddings = np.load(f\"val_numpy_embedding_{exp_name}.npy\", allow_pickle=True)\n",
    "    test_embeddings = np.load(f\"test_numpy_embedding_{exp_name}.npy\", allow_pickle=True)\n",
    "    train_df[\"embedding\"] = train_embeddings\n",
    "    val_df[\"embedding\"] = val_embeddings\n",
    "    test_df[\"embedding\"] = test_embeddings\n",
    "    return train_df, val_df, test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = FungiTastic(root=data_path, split='train', transform=None)\n",
    "val_dataset = FungiTastic(root=data_path, split='val', transform=None)\n",
    "test_dataset = FungiTastic(root=data_path, split='test', transform=None)\n",
    "train_dataset.df, val_dataset.df, test_dataset.df = load_artifacts(exp_name)\n",
    "train_dataset.df_bak, val_dataset.df_bak, test_dataset.df_bak = train_dataset.df.copy(), val_dataset.df.copy(), test_dataset.df.copy()\n",
    "embed_dims = np.load(f\"numpy_embed_dims_{exp_name}.npy\", allow_pickle=True)\n",
    "with open(f\"config_{exp_name}.json\", 'r') as file:\n",
    "    config = json.load(file)\n",
    "config[\"emb_dims\"] = embed_dims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dinov2L_exp_name = \"dinov2L_cache\"\n",
    "dinov2L_train_dataset = FungiTastic(root=data_path, split='train', transform=None)\n",
    "dinov2L_val_dataset = FungiTastic(root=data_path, split='val', transform=None)\n",
    "dinov2L_test_dataset = FungiTastic(root=data_path, split='test', transform=None)\n",
    "dinov2L_train_dataset.df, dinov2L_val_dataset.df, dinov2L_test_dataset.df = load_artifacts(dinov2L_exp_name)\n",
    "dinov2L_embed_dims = np.load(f\"numpy_embed_dims_{dinov2L_exp_name}.npy\", allow_pickle=True)\n",
    "with open(f\"config_{dinov2L_exp_name}.json\", 'r') as file:\n",
    "    dinov2L_config = json.load(file)\n",
    "dinov2L_config[\"emb_dims\"] = dinov2L_embed_dims"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config[\"models\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dinov2L_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dims = {m:ed for m, ed in zip(config['models'], config['emb_dims'])}\n",
    "\n",
    "start_indices = {}\n",
    "cumulative_dim = 0\n",
    "for model_name, dim in model_dims.items():\n",
    "    start_indices[model_name] = cumulative_dim\n",
    "    cumulative_dim += dim\n",
    "\n",
    "def merge_embeddings(df, dinoL_df, config, keep_dinov2b=False):\n",
    "    if not keep_dinov2b:\n",
    "        models = [model for model in config[\"models\"] if not model.startswith(\"DINO\")]\n",
    "        print(f\"keeping {models}\")\n",
    "        keep_slices = []\n",
    "        for model in models:\n",
    "            start_idx = start_indices[model]\n",
    "            end_idx = model_dims[model] + start_idx\n",
    "            keep_slices.append([start_idx, end_idx])\n",
    "        df[\"embedding\"] = df[\"embedding\"].apply(lambda emb: get_combined_embedding(emb, keep_slices))\n",
    "\n",
    "    df_embedding = np.vstack(df[\"embedding\"].to_numpy())\n",
    "    dinov2L_df_embedding = np.vstack(dinoL_df[\"embedding\"].to_numpy())\n",
    "\n",
    "    print(df_embedding.shape)\n",
    "    print(dinov2L_df_embedding.shape)\n",
    "    \n",
    "    combined = np.concatenate([df_embedding, dinov2L_df_embedding], axis=-1)\n",
    "\n",
    "    print(combined.shape)\n",
    "\n",
    "    df[\"embedding\"] = [c for c in combined]\n",
    "    \n",
    "    return df\n",
    "\n",
    "def get_combined_embedding(emb, keep_slices):\n",
    "    model_embeddings = [emb[...,start:end] for start, end in keep_slices]\n",
    "    return np.concatenate(model_embeddings, axis=-1)\n",
    "\n",
    "def update_config(config, dinov2L_config, keep_dinov2b=False):\n",
    "    updated_models = []\n",
    "    updated_emb_dims = []\n",
    "    for model, emb_dim in zip(config[\"models\"], config[\"emb_dims\"]):\n",
    "        if model.startswith(\"DINO\") and not keep_dinov2b:\n",
    "            continue\n",
    "        else:\n",
    "            updated_models.append(model)\n",
    "            updated_emb_dims.append(emb_dim)\n",
    "    updated_models.append(dinov2L_config[\"models\"][0])\n",
    "    updated_emb_dims.append(dinov2L_config[\"emb_dims\"][0])\n",
    "    config[\"models\"] = updated_models\n",
    "    config[\"emb_dims\"] = updated_emb_dims\n",
    "    return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.vstack(train_dataset.df.embedding.to_numpy()).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.vstack(dinov2L_train_dataset.df.embedding.to_numpy()).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.concatenate([np.vstack(train_dataset.df[\"embedding\"].to_numpy()), np.vstack(dinov2L_train_dataset.df[\"embedding\"].to_numpy())], axis=-1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset.df = merge_embeddings(train_dataset.df, dinov2L_train_dataset.df, config, keep_dinov2b=True)\n",
    "val_dataset.df = merge_embeddings(val_dataset.df, dinov2L_val_dataset.df, config, keep_dinov2b=True)\n",
    "test_dataset.df = merge_embeddings(test_dataset.df, dinov2L_test_dataset.df, config, keep_dinov2b=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset.df.embedding.to_numpy()[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dinov2L_train_dataset.df.embedding.to_numpy()[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = update_config(config, dinov2L_config, keep_dinov2b=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset.df[\"embed_dims\"] = [config[\"emb_dims\"] for i in range(len(train_dataset.df))]\n",
    "train_dataset.df[\"emb_dims\"] = [config[\"emb_dims\"] for i in range(len(train_dataset.df))]\n",
    "val_dataset.df[\"embed_dims\"] = [config[\"emb_dims\"] for i in range(len(val_dataset.df))]\n",
    "val_dataset.df[\"emb_dims\"] = [config[\"emb_dims\"] for i in range(len(val_dataset.df))]\n",
    "test_dataset.df[\"embed_dims\"] = [config[\"emb_dims\"] for i in range(len(test_dataset.df))]\n",
    "test_dataset.df[\"emb_dims\"] = [config[\"emb_dims\"] for i in range(len(test_dataset.df))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset.df_bak, val_dataset.df_bak, test_dataset.df_bak = train_dataset.df.copy(), val_dataset.df.copy(), test_dataset.df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Delete dinov2L from memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del dinov2L_train_dataset, dinov2L_val_dataset, dinov2L_test_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge SAM-H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samh_exp_name = \"SAMH_cache\"\n",
    "samh_train_dataset = FungiTastic(root=data_path, split='train', transform=None)\n",
    "samh_val_dataset = FungiTastic(root=data_path, split='val', transform=None)\n",
    "samh_test_dataset = FungiTastic(root=data_path, split='test', transform=None)\n",
    "samh_train_dataset.df, samh_val_dataset.df, samh_test_dataset.df = load_artifacts(samh_exp_name)\n",
    "samh_embed_dims = np.load(f\"numpy_embed_dims_{samh_exp_name}.npy\", allow_pickle=True)\n",
    "with open(f\"config_{samh_exp_name}.json\", 'r') as file:\n",
    "    samh_config = json.load(file)\n",
    "samh_config[\"emb_dims\"] = samh_embed_dims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_embeddings(df, dinoL_df, config, keep_dinov2b=False):\n",
    "\n",
    "    print(\"all transforms\", df.shape)\n",
    "    extra_transforms_df = df[~(df[\"transformation\"].isin(dinoL_df[\"transformation\"].unique()))]\n",
    "    df = df[df[\"transformation\"].isin(dinoL_df[\"transformation\"].unique())]\n",
    "    print(\"transforms not in samh\", extra_transforms_df.shape)\n",
    "    print(\"transforms in samh\", df.shape)\n",
    "    \n",
    "    if not keep_dinov2b:\n",
    "        models = [model for model in config[\"models\"] if not model.startswith(\"DINO\")]\n",
    "        print(f\"keeping {models}\")\n",
    "        keep_slices = []\n",
    "        for model in models:\n",
    "            start_idx = start_indices[model]\n",
    "            end_idx = model_dims[model] + start_idx\n",
    "            keep_slices.append([start_idx, end_idx])\n",
    "        df[\"embedding\"] = df[\"embedding\"].apply(lambda emb: get_combined_embedding(emb, keep_slices))\n",
    "\n",
    "    df_embedding = np.vstack(df[\"embedding\"].to_numpy())\n",
    "    dinov2L_df_embedding = np.vstack(dinoL_df[\"embedding\"].to_numpy())\n",
    "\n",
    "    print(df_embedding.shape)\n",
    "    print(dinov2L_df_embedding.shape)\n",
    "    \n",
    "    combined = np.concatenate([df_embedding, dinov2L_df_embedding], axis=-1)\n",
    "\n",
    "    print(combined.shape)\n",
    "\n",
    "    df[\"embedding\"] = [c for c in combined]\n",
    "\n",
    "    df = pd.concat([df, extra_transforms_df],ignore_index=True)\n",
    "    print(\"merged\", df.shape)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset.df = merge_embeddings(train_dataset.df, samh_train_dataset.df, config, keep_dinov2b=True)\n",
    "val_dataset.df = merge_embeddings(val_dataset.df, samh_val_dataset.df, config, keep_dinov2b=True)\n",
    "test_dataset.df = merge_embeddings(test_dataset.df, samh_test_dataset.df, config, keep_dinov2b=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = update_config(config, samh_config, keep_dinov2b=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset.df[\"embed_dims\"] = [config[\"emb_dims\"] for i in range(len(train_dataset.df))]\n",
    "train_dataset.df[\"emb_dims\"] = [config[\"emb_dims\"] for i in range(len(train_dataset.df))]\n",
    "val_dataset.df[\"embed_dims\"] = [config[\"emb_dims\"] for i in range(len(val_dataset.df))]\n",
    "val_dataset.df[\"emb_dims\"] = [config[\"emb_dims\"] for i in range(len(val_dataset.df))]\n",
    "test_dataset.df[\"embed_dims\"] = [config[\"emb_dims\"] for i in range(len(test_dataset.df))]\n",
    "test_dataset.df[\"emb_dims\"] = [config[\"emb_dims\"] for i in range(len(test_dataset.df))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset.df_bak, val_dataset.df_bak, test_dataset.df_bak = train_dataset.df.copy(), val_dataset.df.copy(), test_dataset.df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del samh_train_dataset, samh_val_dataset, samh_test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_artifacts(\"multimodel_cache_Dinov2L_SAMH\", train_dataset, val_dataset, test_dataset, \n",
    "               {k:v for k, v in config.items() if k != \"embed_dims\"})"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 12156235,
     "sourceId": 91448,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30919,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "fungiclef2025",
   "language": "python",
   "name": "fungiclef2025"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
