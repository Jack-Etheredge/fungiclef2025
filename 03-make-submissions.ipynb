{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "formatted"
    ]
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import os\n",
    "import json\n",
    "import yaml\n",
    "from pathlib import Path\n",
    "from types import SimpleNamespace\n",
    "import argparse\n",
    "\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from torchvision import transforms as tfms\n",
    "import torchvision.transforms as T\n",
    "\n",
    "from typing import Sequence, Tuple, Any, Dict, List, Optional, Union\n",
    "import importlib\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.metrics import top_k_accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "formatted"
    ]
   },
   "outputs": [],
   "source": [
    "# path to fungitatsic dataset\n",
    "data_path = Path('~/datasets/fungiclef2025/').expanduser().resolve()\n",
    "# data_path = '/kaggle/input/fungi-clef-2025/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "formatted"
    ]
   },
   "outputs": [],
   "source": [
    "class FungiTastic(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    Dataset class for the FewShot subset of the Danish Fungi dataset (size 300, closed-set).\n",
    "\n",
    "    This dataset loader supports training, validation, and testing splits, and provides\n",
    "    convenient access to images, class IDs, and file paths. It also supports optional\n",
    "    image transformations.\n",
    "    \"\"\"\n",
    "\n",
    "    SPLIT2STR = {'train': 'Train', 'val': 'Val', 'test': 'Test'}\n",
    "\n",
    "    def __init__(self, root: str, split: str = 'val', transform=None):\n",
    "        \"\"\"\n",
    "        Initializes the FungiTastic dataset.\n",
    "\n",
    "        Args:\n",
    "            root (str): The root directory of the dataset.\n",
    "            split (str, optional): The dataset split to use. Must be one of {'train', 'val', 'test'}.\n",
    "                Defaults to 'val'.\n",
    "            transform (callable, optional): Optional transform to be applied on a sample.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.split = split\n",
    "        self.transform = transform\n",
    "        self.df = self._get_df(root, split)\n",
    "\n",
    "        assert \"image_path\" in self.df\n",
    "        if self.split != 'test':\n",
    "            assert \"category_id\" in self.df\n",
    "            self.n_classes = len(self.df['category_id'].unique())\n",
    "            self.category_id2label = {\n",
    "                k: v[0] for k, v in self.df.groupby('category_id')['species'].unique().to_dict().items()\n",
    "            }\n",
    "            self.label2category_id = {\n",
    "                v: k for k, v in self.category_id2label.items()\n",
    "            }\n",
    "\n",
    "    # def add_embeddings(self, embeddings: pd.DataFrame):\n",
    "    #     \"\"\"\n",
    "    #     Updates the dataset instance with new embeddings.\n",
    "\n",
    "    #     Args:\n",
    "    #         embeddings (pd.DataFrame): A DataFrame containing an 'embedding' column.\n",
    "    #                                    It must align with `self.df` in terms of indexing.\n",
    "    #     \"\"\"\n",
    "    #     assert isinstance(embeddings, pd.DataFrame), \"Embeddings must be a pandas DataFrame.\"\n",
    "    #     assert \"embedding\" in embeddings.columns, \"Embeddings DataFrame must have an 'embedding' column.\"\n",
    "    #     assert len(embeddings) == len(self.df), \"Embeddings must match dataset length.\"\n",
    "\n",
    "    #     self.df = pd.merge(self.df, embeddings, on=\"filename\", how=\"inner\")\n",
    "\n",
    "    def add_embeddings(self, embeddings: pd.DataFrame):\n",
    "        \"\"\"\n",
    "        Updates the dataset instance with new embeddings.\n",
    "    \n",
    "        Args:\n",
    "            embeddings (pd.DataFrame): A DataFrame containing 'filename', 'transformation', \n",
    "                                      and 'embedding' columns.\n",
    "        \"\"\"\n",
    "        assert isinstance(embeddings, pd.DataFrame), \"Embeddings must be a pandas DataFrame.\"\n",
    "        assert \"embedding\" in embeddings.columns, \"Embeddings DataFrame must have an 'embedding' column.\"\n",
    "        assert \"transformation\" in embeddings.columns, \"Embeddings DataFrame must have a 'transformation' column.\"\n",
    "        \n",
    "        # Merge on both filename and transformation\n",
    "        self.df = pd.merge(self.df, embeddings, on=[\"filename\"], how=\"left\")\n",
    "        \n",
    "        # Make sure we have embeddings for at least the original images\n",
    "        assert not self.df[self.df[\"transformation\"] == \"original\"][\"embedding\"].isna().any(), \\\n",
    "            \"Missing embeddings for some original images\"\n",
    "\n",
    "    def get_embeddings_for_class(self, id):\n",
    "        # return the embeddings for class class_idx\n",
    "        class_idxs = self.df[self.df['category_id'] == id].index\n",
    "        return self.df.iloc[class_idxs]['embedding']\n",
    "    \n",
    "    @staticmethod\n",
    "    def _get_df(data_path: str, split: str) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Loads the dataset metadata as a pandas DataFrame.\n",
    "\n",
    "        Args:\n",
    "            data_path (str): The root directory where the dataset is stored.\n",
    "            split (str): The dataset split to load. Must be one of {'train', 'val', 'test'}.\n",
    "\n",
    "        Returns:\n",
    "            pd.DataFrame: A DataFrame containing metadata and file paths for the split.\n",
    "        \"\"\"\n",
    "        df_path = os.path.join(\n",
    "            data_path,\n",
    "            \"metadata\",\n",
    "            \"FungiTastic-FewShot\",\n",
    "            f\"FungiTastic-FewShot-{FungiTastic.SPLIT2STR[split]}.csv\"\n",
    "        )\n",
    "        df = pd.read_csv(df_path)\n",
    "        df[\"image_path\"] = df.filename.apply(\n",
    "            lambda x: os.path.join(data_path, \"FungiTastic-FewShot\", split, '500p', x)  # TODO: 300p to fullsize if different embedder that can handle it\n",
    "        )\n",
    "        return df\n",
    "\n",
    "    def __getitem__(self, idx: int):\n",
    "        \"\"\"\n",
    "        Retrieves a single data sample by index.\n",
    "    \n",
    "        Args:\n",
    "            idx (int): Index of the sample to retrieve.\n",
    "            ret_image (bool, optional): Whether to explicitly return the image. Defaults to False.\n",
    "    \n",
    "        Returns:\n",
    "            tuple:\n",
    "                - If embeddings exist: (image?, embedding, category_id, file_path)\n",
    "                - If no embeddings: (image, category_id, file_path) (original version)\n",
    "        \"\"\"\n",
    "        file_path = self.df[\"image_path\"].iloc[idx].replace('FungiTastic-FewShot', 'images/FungiTastic-FewShot')\n",
    "    \n",
    "        if self.split != 'test':\n",
    "            category_id = self.df[\"category_id\"].iloc[idx]\n",
    "        else:\n",
    "            category_id = None\n",
    "\n",
    "        image = Image.open(file_path)\n",
    "    \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "    \n",
    "        # Check if embeddings exist\n",
    "        if \"embedding\" in self.df.columns:\n",
    "            emb = torch.tensor(self.df.iloc[idx]['embedding'], dtype=torch.float32).squeeze()\n",
    "        else:\n",
    "            emb = None  # No embeddings available\n",
    "    \n",
    "\n",
    "        return image, category_id, file_path, emb\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        Returns the number of samples in the dataset.\n",
    "        \"\"\"\n",
    "        return len(self.df)\n",
    "\n",
    "    def get_class_id(self, idx: int) -> int:\n",
    "        \"\"\"\n",
    "        Returns the class ID of a specific sample.\n",
    "        \"\"\"\n",
    "        return self.df[\"category_id\"].iloc[idx]\n",
    "\n",
    "    def show_sample(self, idx: int) -> None:\n",
    "        \"\"\"\n",
    "        Displays a sample image along with its class name and index.\n",
    "        \"\"\"\n",
    "        image, category_id, _, _ = self.__getitem__(idx)\n",
    "        class_name = self.category_id2label[category_id]\n",
    "\n",
    "        plt.imshow(image)\n",
    "        plt.title(f\"Class: {class_name}; id: {idx}\")\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "\n",
    "    def get_category_idxs(self, category_id: int) -> List[int]:\n",
    "        \"\"\"\n",
    "        Retrieves all indexes for a given category ID.\n",
    "        \"\"\"\n",
    "        return self.df[self.df.category_id == category_id].index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Load the datasets\n",
    "\n",
    "train_dataset = FungiTastic(root=data_path, split='train', transform=None)\n",
    "val_dataset = FungiTastic(root=data_path, split='val', transform=None)\n",
    "test_dataset = FungiTastic(root=data_path, split='test', transform=None)\n",
    "\n",
    "# train_dataset.df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_dataset.df.image_path.to_numpy()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_dataset.df.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading, saving, computing embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_name = \"multimodel_cache_Dinov2L_SAMH\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import json\n",
    "    \n",
    "def save_artifacts(exp_name, train_dataset, val_dataset, test_dataset, config, overwrite=False):\n",
    "    file = Path(f\"numpy_embed_dims_{exp_name}.npy\")\n",
    "    if file.exists() and not overwrite:\n",
    "        raise FileExistsError(\"overwrite is False and artifacts exist.\")\n",
    "    embed_dims = test_dataset.df.emb_dims.iloc[0]\n",
    "    np.save(f\"numpy_embed_dims_{exp_name}.npy\", embed_dims)\n",
    "    train_dataset.df.to_csv(f\"train_df_{exp_name}.csv\", index=None)\n",
    "    val_dataset.df.to_csv(f\"val_df_{exp_name}.csv\", index=None)\n",
    "    test_dataset.df.to_csv(f\"test_df_{exp_name}.csv\", index=None)\n",
    "    np.save(f\"train_numpy_embedding_{exp_name}.npy\", train_dataset.df.embedding.to_numpy())\n",
    "    np.save(f\"val_numpy_embedding_{exp_name}.npy\", val_dataset.df.embedding.to_numpy())\n",
    "    np.save(f\"test_numpy_embedding_{exp_name}.npy\", test_dataset.df.embedding.to_numpy())\n",
    "    with open(f\"config_{exp_name}.json\", \"w\") as f:\n",
    "        json.dump(config, f, sort_keys=True, indent=4)\n",
    "\n",
    "def load_artifacts(exp_name):\n",
    "    train_df = pd.read_csv(f\"train_df_{exp_name}.csv\")\n",
    "    val_df = pd.read_csv(f\"val_df_{exp_name}.csv\")\n",
    "    test_df = pd.read_csv(f\"test_df_{exp_name}.csv\")\n",
    "    embed_dims = np.load(f\"numpy_embed_dims_{exp_name}.npy\", allow_pickle=True)\n",
    "    train_df['embed_dims'] = train_df.apply(lambda row: embed_dims, axis=1)\n",
    "    val_df['embed_dims'] = val_df.apply(lambda row: embed_dims, axis=1)\n",
    "    test_df['embed_dims'] = test_df.apply(lambda row: embed_dims, axis=1)\n",
    "    train_embeddings = np.load(f\"train_numpy_embedding_{exp_name}.npy\", allow_pickle=True)\n",
    "    val_embeddings = np.load(f\"val_numpy_embedding_{exp_name}.npy\", allow_pickle=True)\n",
    "    test_embeddings = np.load(f\"test_numpy_embedding_{exp_name}.npy\", allow_pickle=True)\n",
    "    train_df[\"embedding\"] = train_embeddings\n",
    "    val_df[\"embedding\"] = val_embeddings\n",
    "    test_df[\"embedding\"] = test_embeddings\n",
    "    return train_df, val_df, test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = FungiTastic(root=data_path, split='train', transform=None)\n",
    "val_dataset = FungiTastic(root=data_path, split='val', transform=None)\n",
    "test_dataset = FungiTastic(root=data_path, split='test', transform=None)\n",
    "train_dataset.df, val_dataset.df, test_dataset.df = load_artifacts(exp_name)\n",
    "train_dataset.df_bak, val_dataset.df_bak, test_dataset.df_bak = train_dataset.df.copy(), val_dataset.df.copy(), test_dataset.df.copy()\n",
    "embed_dims = np.load(f\"numpy_embed_dims_{exp_name}.npy\", allow_pickle=True)\n",
    "with open(f\"config_{exp_name}.json\", 'r') as file:\n",
    "    config = json.load(file)\n",
    "config[\"emb_dims\"] = embed_dims"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manipulating the datasets (reload to clear manipulations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reset_dfs(dataset_list):\n",
    "    \"\"\"reset dfs to their original state before manipulation\"\"\"\n",
    "    for dataset in dataset_list:\n",
    "        dataset.df = dataset.df_bak.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.functional import cross_entropy, normalize, softmax\n",
    "import copy\n",
    "import math\n",
    "\n",
    "class EmbeddingDataset(Dataset):\n",
    "    def __init__(self, dataframe):\n",
    "        self.df = dataframe\n",
    "        self.embeddings = dataframe['embedding'].values\n",
    "        self.labels = dataframe['category_id'].values\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        emb = torch.tensor(self.embeddings[idx], dtype=torch.float32).squeeze()\n",
    "        label = torch.tensor(self.labels[idx], dtype=torch.long)\n",
    "        return emb, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProjectionModel(torch.nn.Module):\n",
    "    def __init__(self, input_dim, embedder_dims, projection_dim=512, use_layernorm=False, use_dropout=False, dropout_rate=0.1, \n",
    "                 internal_dim=1024, use_attention=False, attention_dim=512, extra_layer=False):\n",
    "        super().__init__()\n",
    "        self.use_attention = use_attention\n",
    "        self.num_embedders = len(embedder_dims) if use_attention else None\n",
    "        self.embedder_dims = embedder_dims if use_attention else None\n",
    "        self.fixed_dim = attention_dim\n",
    "\n",
    "        if use_attention:\n",
    "            self.attn_weights = torch.nn.Parameter(torch.ones(self.num_embedders))\n",
    "            # ensures we can stack the embeddings\n",
    "            self.attn_projections = nn.ModuleList([\n",
    "                torch.nn.Sequential(torch.nn.Linear(emb_dim, self.fixed_dim), torch.nn.ReLU()) for emb_dim in embedder_dims\n",
    "            ])\n",
    "        \n",
    "        layers = [\n",
    "            torch.nn.Linear(self.fixed_dim if use_attention else input_dim, internal_dim * 2 if extra_layer else internal_dim),\n",
    "            torch.nn.ReLU()\n",
    "        ]\n",
    "\n",
    "        if use_layernorm:\n",
    "            layers.append(torch.nn.LayerNorm(internal_dim))\n",
    "        if use_dropout:\n",
    "            layers.append(torch.nn.Dropout(dropout_rate))\n",
    "\n",
    "        if extra_layer:\n",
    "            layers.extend([torch.nn.Linear(internal_dim * 2, internal_dim), torch.nn.ReLU()])\n",
    "\n",
    "        layers.append(torch.nn.Linear(internal_dim, projection_dim))\n",
    "\n",
    "        if use_layernorm:\n",
    "            layers.append(torch.nn.LayerNorm(projection_dim))\n",
    "\n",
    "        self.projection = torch.nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.use_attention:\n",
    "            if x.dim() == 3 and x.shape[1] == 1:\n",
    "                x = x.squeeze(1)  # Squeeze out the second dimension\n",
    "            # split the embeddings out\n",
    "            start = 0\n",
    "            embeddings = []\n",
    "            for emb_dim, proj_layer in zip(self.embedder_dims, self.attn_projections):\n",
    "                embedding = x[:, start:start + emb_dim]\n",
    "                projected_embedding = proj_layer(embedding)\n",
    "                embeddings.append(projected_embedding)\n",
    "                start += emb_dim\n",
    "            weights = softmax(self.attn_weights, dim=0)\n",
    "            # for embed in embeddings:\n",
    "            #     print(embed.shape)\n",
    "            x = torch.stack([w * e for w, e in zip(weights, embeddings)], dim=0).sum(dim=0)\n",
    "            # print(\"after attention projections:\", x.shape)\n",
    "            x = self.projection(x)\n",
    "            # print(\"after final projection:\", x.shape)\n",
    "        else:\n",
    "            x = self.projection(normalize(x, p=2, dim=-1))\n",
    "        # x = self.projection(x)\n",
    "        return normalize(x, p=2, dim=-1)\n",
    "\n",
    "class CosineClassifier(torch.nn.Module):\n",
    "    \"\"\"Classifier to train the ProjectionModel\"\"\"\n",
    "    def __init__(self, embed_dim, num_classes, scale=10.0):\n",
    "        super().__init__()\n",
    "        self.weight = torch.nn.Parameter(torch.randn(num_classes, embed_dim))\n",
    "        self.scale = scale  # Optional learnable scaling\n",
    "        torch.nn.init.kaiming_uniform_(self.weight, a=math.sqrt(5))\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: [B, D]\n",
    "        x = normalize(x, p=2, dim=-1)\n",
    "        w = normalize(self.weight, p=2, dim=-1)\n",
    "        return self.scale * torch.matmul(x, w.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import copy\n",
    "import torch.nn.functional as F\n",
    "from pytorch_metric_learning.losses import NTXentLoss\n",
    "\n",
    "\n",
    "def train(model, classifier, train_loader, val_loader, num_epochs=300, patience=5, lr=1e-5, device='cuda'):\n",
    "    return _train_ce_infonce(model, classifier, train_loader, val_loader, num_epochs, patience, lr, device)\n",
    "\n",
    "class LearnableLossWeighting(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # Initialize log variances as learnable parameters\n",
    "        self.log_sigma_ce = torch.nn.Parameter(torch.tensor(0.0))\n",
    "        self.log_sigma_triplet = torch.nn.Parameter(torch.tensor(0.0))\n",
    "\n",
    "    def forward(self, ce_loss, triplet_loss):\n",
    "        # From Kendall et al. CVPR 2018\n",
    "        loss = (\n",
    "            torch.exp(-self.log_sigma_ce) * ce_loss +\n",
    "            torch.exp(-self.log_sigma_triplet) * triplet_loss +\n",
    "            self.log_sigma_ce + self.log_sigma_triplet\n",
    "        )\n",
    "        return 0.5 * loss\n",
    "\n",
    "def _train_ce_infonce(\n",
    "    model,\n",
    "    classifier,\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    num_epochs,\n",
    "    patience,\n",
    "    lr,\n",
    "    device,\n",
    "    lambda_triplet=None\n",
    "):\n",
    "    model.to(device)\n",
    "    classifier.to(device)\n",
    "    if lambda_triplet == \"learned\" or lambda_triplet is None:\n",
    "        loss_weighter = LearnableLossWeighting().to(device)\n",
    "        optimizer = torch.optim.AdamW(\n",
    "            list(model.parameters()) +\n",
    "            list(classifier.parameters()) +\n",
    "            list(loss_weighter.parameters()), \n",
    "            lr=lr, weight_decay=1e-4\n",
    "        )\n",
    "    elif isinstance(lambda_triplet, float) or isinstance(lambda_triplet, int):\n",
    "        optimizer = torch.optim.AdamW(\n",
    "            list(model.parameters()) + list(classifier.parameters()), \n",
    "            lr=lr, \n",
    "            weight_decay=1e-4\n",
    "        )\n",
    "\n",
    "    infonce_loss_func = NTXentLoss(temperature=0.07).to(device)\n",
    "\n",
    "    best_val_loss = float('inf')\n",
    "    best_model_state = None\n",
    "    best_classifier_state = None\n",
    "    patience_counter = 0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        classifier.train()\n",
    "        total_loss = 0.0\n",
    "        ce_loss_total = 0.0\n",
    "        triplet_loss_total = 0.0\n",
    "\n",
    "        for x, y in train_loader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "\n",
    "            embeddings = model(x)\n",
    "            logits = classifier(embeddings)\n",
    "\n",
    "            # Cross-entropy\n",
    "            ce_loss = F.cross_entropy(logits, y)\n",
    "\n",
    "            infonce_loss = infonce_loss_func(embeddings, y)\n",
    "\n",
    "            # Combined loss\n",
    "            if lambda_triplet == \"learned\" or lambda_triplet is None:\n",
    "                loss = loss_weighter(ce_loss, infonce_loss)\n",
    "            elif isinstance(lambda_triplet, float) or isinstance(lambda_triplet, int):\n",
    "                loss = ce_loss + lambda_triplet * infonce_loss\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            ce_loss_total += ce_loss.item()\n",
    "            triplet_loss_total += infonce_loss.item()\n",
    "\n",
    "        # Validation\n",
    "        model.eval()\n",
    "        classifier.eval()\n",
    "        val_loss = 0.0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for x, y in val_loader:\n",
    "                x, y = x.to(device), y.to(device)\n",
    "                embeddings = model(x)\n",
    "                logits = classifier(embeddings)\n",
    "                ce_loss = F.cross_entropy(logits, y)\n",
    "\n",
    "                infonce_loss = infonce_loss_func(embeddings, y)\n",
    "\n",
    "                if lambda_triplet == \"learned\" or lambda_triplet is None:\n",
    "                    val_loss += (loss_weighter(ce_loss, infonce_loss)).item()\n",
    "                elif isinstance(lambda_triplet, float) or isinstance(lambda_triplet, int):\n",
    "                    val_loss += (ce_loss + lambda_triplet * infonce_loss).item()\n",
    "\n",
    "        avg_val_loss = val_loss / len(val_loader)\n",
    "        print(\n",
    "            f\"Epoch {epoch+1:3d} | \"\n",
    "            f\"Train CE: {ce_loss_total:.4f} | \"\n",
    "            f\"InfoNCE: {triplet_loss_total:.4f} | \"\n",
    "            f\"Total: {total_loss:.4f} | \"\n",
    "            f\"Val Loss: {avg_val_loss:.4f}\"\n",
    "        )\n",
    "\n",
    "        if avg_val_loss < best_val_loss:\n",
    "            best_val_loss = avg_val_loss\n",
    "            best_model_state = copy.deepcopy(model.state_dict())\n",
    "            best_classifier_state = copy.deepcopy(classifier.state_dict())\n",
    "            patience_counter = 0\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter >= patience:\n",
    "                print(\"Early stopping.\")\n",
    "                break\n",
    "\n",
    "    model.load_state_dict(best_model_state)\n",
    "    classifier.load_state_dict(best_classifier_state)\n",
    "    return model, classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit projection network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Top-5 Accuracy against validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PrototypeClassifier(torch.nn.Module):\n",
    "    def __init__(self, train_dataset, projection_model, device='cuda'):\n",
    "        super().__init__()\n",
    "        self.device = device\n",
    "        self.train_dataset = train_dataset\n",
    "        self.projection_model = projection_model.to(self.device)\n",
    "        self.projection_model.eval()\n",
    "\n",
    "        class_embeddings, _ = self._get_classifier_embeddings(train_dataset)\n",
    "        print(\"class embeddings shape before projection:\", class_embeddings[0].shape)\n",
    "        self.class_embeddings = [self.projection_model(class_embedding.to(device)) for class_embedding in class_embeddings]\n",
    "        print(\"class embeddings shape after projection:\", self.class_embeddings[0].shape)\n",
    "        \n",
    "        self.class_prototypes = torch.nn.Parameter(self.get_mean_prototypes(self.class_embeddings), requires_grad=False)\n",
    "        \n",
    "        print(\"prototypes shape:\", self.class_prototypes.shape)\n",
    "\n",
    "    def _get_classifier_embeddings(self, dataset_train):\n",
    "        class_embeddings = []\n",
    "        empty_classes = []\n",
    "        n_classes = min(torch.inf, dataset_train.n_classes)\n",
    "        for cls in range(n_classes):\n",
    "            cls_embs = dataset_train.get_embeddings_for_class(cls)\n",
    "            if len(cls_embs) == 0:\n",
    "                # if no embeddings for class, use zeros\n",
    "                empty_classes.append(cls)\n",
    "                class_embeddings.append(torch.zeros(1, dataset_train.emb_dim))\n",
    "            else:\n",
    "                class_embeddings.append(torch.tensor(np.vstack(cls_embs.values)))\n",
    "        return class_embeddings, empty_classes\n",
    "\n",
    "    def get_mean_prototypes(self, embeddings):\n",
    "        # return normalize(torch.stack([class_embs.mean(dim=0) for class_embs in embeddings]), p=2, dim=-1)\n",
    "        return torch.stack([class_embs.mean(dim=0) for class_embs in embeddings])\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def make_prediction(self, embeddings):\n",
    "        embeddings = embeddings.to(self.device)\n",
    "        embeddings = self.projection_model(embeddings)\n",
    "        # print(embeddings.shape)\n",
    "        # print(self.class_prototypes.shape)\n",
    "        if embeddings.dim() == 2 and embeddings.shape[1] != 1:\n",
    "            embeddings = embeddings.unsqueeze(1)\n",
    "\n",
    "        embeddings = normalize(embeddings, p=2, dim=-1)\n",
    "\n",
    "        similarities = torch.nn.functional.cosine_similarity(embeddings, self.class_prototypes, dim=-1)\n",
    "        # print(\"similarities\", similarities.shape)\n",
    "        # print(\"similarities[0]\", similarities[0].shape)\n",
    "        # top_5 = torch.topk(similarities, k=5, dim=1)\n",
    "        # top_10 = torch.topk(similarities, k=10, dim=1)\n",
    "        probas = torch.nn.functional.softmax(similarities, dim=1).detach().cpu()\n",
    "        return probas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset.df.embedding[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset.df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_val_probas(train_dataset, eval_dataset, format_for_submission=False, batch_size=10, reduction=\"mean\", projection_model=None):\n",
    "\n",
    "    proba_accumulator = {}\n",
    "    \n",
    "    query_embeddings = None\n",
    "\n",
    "    if projection_model is None:\n",
    "        projection_model = fitted_embedding_projection_model\n",
    "        \n",
    "    classifier = PrototypeClassifier(train_dataset, projection_model=projection_model, device='cpu')\n",
    "    \n",
    "    print(f\"Class prototypes shape: {classifier.class_prototypes.shape}\")\n",
    "    \n",
    "    # Initialize a dictionary to store predictions\n",
    "    predictions = {}\n",
    "    \n",
    "    # Process in batches\n",
    "    unique_observation_ids = eval_dataset.df[\"observationID\"].unique()\n",
    "    for i in range(0, len(unique_observation_ids), batch_size):\n",
    "        batch_ids = unique_observation_ids[i:i+batch_size]\n",
    "        batch_data = eval_dataset.df[eval_dataset.df[\"observationID\"].isin(batch_ids)]\n",
    "        \n",
    "        # Process each filename group in this batch\n",
    "        batch_embeddings = []\n",
    "        batch_filenames = []\n",
    "        \n",
    "        for filename, group in batch_data.groupby(\"observationID\", sort=False):\n",
    "            embeddings_array = group[\"embedding\"].to_numpy()\n",
    "            embeddings_array = np.vstack(embeddings_array).squeeze()\n",
    "            if reduction == \"median\":\n",
    "                avg_embedding = np.median(embeddings_array, axis=0, keepdims=True).squeeze()\n",
    "            elif reduction == \"mean\":\n",
    "                avg_embedding = np.mean(embeddings_array, axis=0, keepdims=True).squeeze()\n",
    "            \n",
    "            batch_embeddings.append(avg_embedding)\n",
    "            batch_filenames.append(filename)\n",
    "        \n",
    "        # Convert to tensor and make predictions\n",
    "        avg_embeddings = torch.tensor(np.array(batch_embeddings), dtype=torch.float32)\n",
    "        probas = classifier.make_prediction(avg_embeddings)\n",
    "        \n",
    "        # # Add to predictions dictionary\n",
    "        # for fname, pred in zip(batch_filenames, top_5.indices.numpy()):\n",
    "        #     predictions[fname] = pred\n",
    "            \n",
    "        for fname, proba in zip(batch_filenames, probas):\n",
    "            proba_accumulator[fname] = proba.clone()\n",
    "        \n",
    "        # Free memory\n",
    "        del avg_embeddings, batch_embeddings, batch_data\n",
    "    \n",
    "    return proba_accumulator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def get_submission_from_summed_probas(eval_dataset, proba_accumulator, format_for_submission=False, k=5):\n",
    "    # Final prediction dictionary\n",
    "    final_predictions = {}\n",
    "    \n",
    "    # For each observation, get top-5 from accumulated probabilities\n",
    "    for fname, proba in proba_accumulator.items():\n",
    "        top5 = torch.topk(proba, k=k)\n",
    "        final_predictions[fname] = top5.indices.numpy()  # or top5.values if needed too\n",
    "    \n",
    "    # Map predictions back to eval dataset\n",
    "    eval_dataset.df[\"preds\"] = eval_dataset.df[\"observationID\"].map(final_predictions)\n",
    "    \n",
    "    submission = eval_dataset.df.copy()\n",
    "    submission = submission.drop_duplicates(subset=\"observationID\")\n",
    "    \n",
    "    if format_for_submission:\n",
    "        submission = submission[[\"observationID\", \"preds\"]]\n",
    "        submission['preds'] = submission['preds'].apply(lambda x: ' '.join(map(str, x)))\n",
    "\n",
    "    return submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_hot_encode(data, num_classes):\n",
    "    \"\"\"\n",
    "    Encodes a list of lists of categories into a multi-hot encoded numpy array.\n",
    "\n",
    "    Args:\n",
    "        data: A list of lists, where each inner list represents the categories present in an instance.\n",
    "        num_classes: The total number of unique categories.\n",
    "\n",
    "    Returns:\n",
    "        A numpy array of shape (len(data), num_classes) representing the multi-hot encoded data.\n",
    "    \"\"\"\n",
    "    encoded_data = np.zeros((len(data), num_classes), dtype=int)\n",
    "    for i, instance_categories in enumerate(data):\n",
    "        for category_index in instance_categories:\n",
    "          if 0 <= category_index < num_classes:\n",
    "            encoded_data[i, category_index] = 1\n",
    "    return encoded_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedder_dims = config[\"emb_dims\"]\n",
    "embedder_dims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dims = {m:ed for m, ed in zip(config['models'], config['emb_dims'])}\n",
    "\n",
    "start_indices = {}\n",
    "cumulative_dim = 0\n",
    "for model_name, dim in model_dims.items():\n",
    "    start_indices[model_name] = cumulative_dim\n",
    "    cumulative_dim += dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit the projection model and evaluate the validation top5 accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def slice_embedding(df, models):\n",
    "    if not all(model in model_dims for model in models):\n",
    "        missing = [m for m in models if m not in model_dims]\n",
    "        raise ValueError(f\"Models not found in configuration: {missing}\")\n",
    "    keep_slices = []\n",
    "    for model in models:\n",
    "        start_idx = start_indices[model]\n",
    "        end_idx = model_dims[model] + start_idx\n",
    "        keep_slices.append([start_idx, end_idx])\n",
    "    df[\"embedding\"] = df[\"embedding\"].apply(lambda emb: get_combined_embedding(emb, keep_slices))\n",
    "    return df\n",
    "\n",
    "\n",
    "def get_combined_embedding(emb, keep_slices):\n",
    "    model_embeddings = [emb[...,start:end] for start, end in keep_slices]\n",
    "    return np.concatenate(model_embeddings, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "def split_probability(n_obs, max_prob=0.9, steepness=1.0, midpoint=5):\n",
    "    \"\"\"Probabilistic curve for splitting based on number of observations.\"\"\"\n",
    "    return max_prob / (1 + math.exp(-steepness * (n_obs - midpoint)))\n",
    "\n",
    "def probabilistic_train_val_split(\n",
    "    df: pd.DataFrame,\n",
    "    class_col: str = \"category_id\",\n",
    "    obs_col: str = \"observationID\",\n",
    "    val_frac: float = 0.2,\n",
    "    random_state: int | None = None,\n",
    ") -> tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    rng = np.random.default_rng(random_state)\n",
    "    train_idx, val_idx = [], []\n",
    "\n",
    "    for cls, g in df.groupby(class_col):\n",
    "        obs_ids = g[obs_col].unique()\n",
    "        n_obs = len(obs_ids)\n",
    "\n",
    "        if n_obs == 1:\n",
    "            train_idx.extend(g.index)\n",
    "            continue\n",
    "\n",
    "        p_split = split_probability(n_obs)\n",
    "\n",
    "        if rng.random() > p_split:\n",
    "            train_idx.extend(g.index)\n",
    "            continue\n",
    "\n",
    "        n_val_obs = max(1, int(round(n_obs * val_frac)))\n",
    "        val_obs = rng.choice(obs_ids, size=n_val_obs, replace=False)\n",
    "\n",
    "        val_mask = g[obs_col].isin(val_obs)\n",
    "        val_idx.extend(g[val_mask].index)\n",
    "        train_idx.extend(g[~val_mask].index)\n",
    "\n",
    "    train_df = df.loc[train_idx].reset_index(drop=True)\n",
    "    val_df = df.loc[val_idx].reset_index(drop=True)\n",
    "    return train_df, val_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# illustrate the split probability increasing with n_obs, 0.45 with midpoint observations, capping at 0.9 \n",
    "\n",
    "for i in range(45):\n",
    "    print(i, split_probability(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "best_individual_models = ['DINOv2Base@434', 'DINOv2Large@518', 'FungiTasticBEIT@384']\n",
    "best_individual_augs = ['original', 'center_crop', 'top_left_crop', 'top_right_crop', 'bottom_left_crop', 'bottom_right_crop', \n",
    "                         'horizontal_flip', 'rot_90', 'rot_270', 'rot_15', 'rot_345']\n",
    "\n",
    "# # best individual + SAMH x5 with random train-val split for projection model (0.2, probabilistic splits on image_path)\n",
    "ensmbl_idx = 20\n",
    "model_combos = [\n",
    "    (['FungiTasticBEIT@384', 'DINOv2Base@434', 'DINOv2Large@518', 'SAMViTH@1024'], best_individual_augs, \"ce_infonce\"),  # best mean combo\n",
    "    (['FungiTasticBEIT@384', 'DINOv2Base@434', 'DINOv2Large@518', 'SAMViTH@1024'], best_individual_augs, \"ce_infonce\"),  # best mean combo\n",
    "    (['FungiTasticBEIT@384', 'DINOv2Base@434', 'DINOv2Large@518', 'SAMViTH@1024'], best_individual_augs, \"ce_infonce\"),  # best mean combo\n",
    "    (['FungiTasticBEIT@384', 'DINOv2Base@434', 'DINOv2Large@518', 'SAMViTH@1024'], best_individual_augs, \"ce_infonce\"),  # best mean combo\n",
    "    (['FungiTasticBEIT@384', 'DINOv2Base@434', 'DINOv2Large@518', 'SAMViTH@1024'], best_individual_augs, \"ce_infonce\"),  # best mean combo\n",
    "]\n",
    "\n",
    "list_of_projection_models = []\n",
    "list_of_proba_dicts = []\n",
    "for models, augs, loss_type in tqdm(model_combos):\n",
    "    \n",
    "    print(models, augs, loss_type, use_tim, layernorm)\n",
    "    \n",
    "    reset_dfs([train_dataset, val_dataset, test_dataset])\n",
    "    \n",
    "    # create augs subset and slice out the model embeddings subset\n",
    "    train_dataset.df = train_dataset.df[train_dataset.df.transformation.isin(augs)].reset_index(drop=True)\n",
    "    train_dataset.df = slice_embedding(train_dataset.df, models)\n",
    "    val_dataset.df = val_dataset.df[val_dataset.df.transformation.isin(augs)].reset_index(drop=True)\n",
    "    val_dataset.df = slice_embedding(val_dataset.df, models)\n",
    "    test_dataset.df = test_dataset.df[test_dataset.df.transformation.isin(augs)].reset_index(drop=True)\n",
    "    test_dataset.df = slice_embedding(test_dataset.df, models)\n",
    "    \n",
    "    input_dim = train_dataset.df.embedding[0].shape[-1]\n",
    "    print(\"input dim before projection\", input_dim)\n",
    "    num_classes = train_dataset.df.category_id.nunique()\n",
    "    print(\"num classes\", num_classes)\n",
    "    projection_embedder_dimension = 768\n",
    "    print(\"projection embedder dim\", projection_embedder_dimension)\n",
    "    embedder_dims = train_dataset.df[\"emb_dims\"].values[0]\n",
    "    print(\"embedder dims\", embedder_dims)\n",
    "\n",
    "    train_val_df = pd.concat([train_dataset.df, val_dataset.df], ignore_index=True)\n",
    "    train_df, val_df = probabilistic_train_val_split(\n",
    "    train_val_df,\n",
    "    class_col=\"category_id\",\n",
    "    obs_col=\"observationID\",\n",
    "    # obs_col=\"image_path\",\n",
    "    val_frac=0.1,\n",
    "    )\n",
    "    \n",
    "    train_loader = DataLoader(EmbeddingDataset(train_df), batch_size=64, shuffle=True)\n",
    "    val_loader = DataLoader(EmbeddingDataset(val_df), batch_size=64)\n",
    "    \n",
    "    model = ProjectionModel(input_dim=input_dim, embedder_dims=embedder_dims, projection_dim=projection_embedder_dimension, \n",
    "                            use_layernorm=False,\n",
    "                            use_dropout=False, dropout_rate=0.25,\n",
    "                            use_attention=False, attention_dim=512,\n",
    "                            internal_dim=2048, extra_layer=False)\n",
    "    classifier = CosineClassifier(embed_dim=projection_embedder_dimension, num_classes=num_classes)\n",
    "    \n",
    "    fitted_embedding_projection_model, fitted_classifier = train(model, classifier, train_loader, val_loader)\n",
    "    # submission = get_val_predictions(train_dataset, val_dataset, query_aware_prototypes=False, use_tim=use_tim)\n",
    "\n",
    "    probas_dict = get_val_probas(train_dataset, val_dataset, format_for_submission=False, batch_size=10,\n",
    "                                 reduction=\"mean\", projection_model=fitted_embedding_projection_model)\n",
    "    \n",
    "    list_of_proba_dicts.append(probas_dict)\n",
    "    list_of_projection_models.append(fitted_embedding_projection_model)\n",
    "\n",
    "# Create a defaultdict to accumulate summed probabilities\n",
    "summed_probas = defaultdict(lambda: None)\n",
    "# Loop over multiple models' probability outputs\n",
    "for model_probas in list_of_proba_dicts:\n",
    "    for fname, proba in model_probas.items():\n",
    "        if summed_probas[fname] is None:\n",
    "            summed_probas[fname] = proba.clone()\n",
    "        else:\n",
    "            summed_probas[fname] += proba\n",
    "            \n",
    "submission = get_submission_from_summed_probas(val_dataset, summed_probas)\n",
    "\n",
    "labels = train_dataset.df.sort_values(\"category_id\")[\"category_id\"].unique()\n",
    "y_true = submission[\"category_id\"].to_numpy()\n",
    "y_pred = np.array(submission[\"preds\"].to_list())\n",
    "y_pred = multi_hot_encode(y_pred, len(labels))\n",
    "accuracy = top_k_accuracy_score(y_true, y_pred, k=5, labels=labels)\n",
    "row = pd.DataFrame([{\"models\": models, \"augs\": augs, \"accuracy\": accuracy}])\n",
    "display(row)\n",
    "\n",
    "datetimestr = datetime.now().strftime(\"%Y-%m-%d-%H-%M-%S\")\n",
    "# PRED_FILENAME = f\"{datetimestr}-{\"-\".join(models)}-{\"-\".join(augs)}-{loss_type}-{use_tim}-{accuracy:.3f}.csv\"\n",
    "PRED_FILENAME = f\"ensmbl_{ensmbl_idx}-{datetimestr}-{accuracy:.3f}.csv\"\n",
    "print(PRED_FILENAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Average the embeddings over the observationID and use that average embedding to make each classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_proba_dicts_final_submission = []\n",
    "for (models, augs, loss_type), projection_model in tqdm(zip(model_combos, list_of_projection_models), total=len(model_combos)):\n",
    "    \n",
    "    print(models, augs, loss_type, use_tim, layernorm)\n",
    "    \n",
    "    reset_dfs([train_dataset, val_dataset, test_dataset])\n",
    "\n",
    "    # create augs subset and slice out the model embeddings subset\n",
    "    train_dataset.df = train_dataset.df[train_dataset.df.transformation.isin(augs)].reset_index(drop=True)\n",
    "    train_dataset.df = slice_embedding(train_dataset.df, models)\n",
    "    val_dataset.df = val_dataset.df[val_dataset.df.transformation.isin(augs)].reset_index(drop=True)\n",
    "    val_dataset.df = slice_embedding(val_dataset.df, models)\n",
    "    test_dataset.df = test_dataset.df[test_dataset.df.transformation.isin(augs)].reset_index(drop=True)\n",
    "    test_dataset.df = slice_embedding(test_dataset.df, models)\n",
    "\n",
    "    # combine train and val for final prototypes\n",
    "    train_val_dataset = FungiTastic(root=data_path, split='train', transform=None)\n",
    "    train_val_dataset.df = pd.concat([train_dataset.df, val_dataset.df], ignore_index=True)\n",
    "    \n",
    "    # Create a classifier as before\n",
    "    if use_tim:\n",
    "        query_embeddings = []\n",
    "        for group, groupdf in test_dataset.df.groupby(\"observationID\"):\n",
    "            query_embeddings.append(groupdf[\"embedding\"].to_numpy().mean(axis=0))\n",
    "        query_embeddings = np.concatenate(query_embeddings, axis=0)\n",
    "        # query_embeddings = eval_dataset.df[\"embedding\"].to_numpy()\n",
    "        # query_embeddings = np.vstack(query_embeddings)\n",
    "        query_embeddings = torch.tensor(query_embeddings, dtype=torch.float32)\n",
    "    else:\n",
    "        query_embeddings = None\n",
    "    \n",
    "    # Create a classifier as before\n",
    "    classifier = PrototypeClassifier(train_val_dataset, projection_model=projection_model, device='cpu',\n",
    "                                     use_tim=use_tim, query_embeddings=query_embeddings)\n",
    "    \n",
    "    # Debug print the prototype shape\n",
    "    print(f\"Class prototypes shape: {classifier.class_prototypes.shape}\")\n",
    "    \n",
    "    # Initialize lists to store averaged embeddings and filenames\n",
    "    avg_embeddings_list = []\n",
    "    filenames_list = []\n",
    "    \n",
    "    # Process each filename group\n",
    "    for filename, group in test_dataset.df.groupby(\"observationID\", sort=False):\n",
    "        # Convert list of embeddings to array, making sure to squeeze extra dimensions\n",
    "        embeddings_array = group[\"embedding\"].to_numpy()\n",
    "    \n",
    "        embeddings_array = np.vstack(embeddings_array).squeeze()\n",
    "        avg_embedding = np.mean(embeddings_array, axis=0, keepdims=True).squeeze()\n",
    "        \n",
    "        avg_embeddings_list.append(avg_embedding)\n",
    "        filenames_list.append(filename)\n",
    "    \n",
    "    # Convert to tensor\n",
    "    avg_embeddings = torch.tensor(np.array(avg_embeddings_list), dtype=torch.float32)\n",
    "    print(f\"Averaged embeddings shape: {avg_embeddings.shape}\")\n",
    "    \n",
    "    # Make predictions using the averaged embeddings\n",
    "    probas = classifier.make_prediction(avg_embeddings)\n",
    "\n",
    "    # Create a mapping from filenames to predictions\n",
    "    probas_dict = {}\n",
    "    for fname, proba in zip(filenames_list, probas):\n",
    "        probas_dict[fname] = proba.clone()\n",
    "\n",
    "    list_of_proba_dicts_final_submission.append(probas_dict)\n",
    "\n",
    "# Create a defaultdict to accumulate summed probabilities\n",
    "summed_probas = defaultdict(lambda: None)\n",
    "# Loop over multiple models' probability outputs\n",
    "for model_probas in list_of_proba_dicts_final_submission:\n",
    "    for fname, proba in model_probas.items():\n",
    "        if summed_probas[fname] is None:\n",
    "            summed_probas[fname] = proba.clone()\n",
    "        else:\n",
    "            summed_probas[fname] += proba\n",
    "            \n",
    "submission = get_submission_from_summed_probas(test_dataset, summed_probas, format_for_submission=True, k=10)\n",
    "\n",
    "submission = submission.rename(columns={\"observationID\": \"observationId\", \"preds\": \"predictions\"})\n",
    "submission['observationId'] = submission['observationId'].astype('Int64')\n",
    "submission.to_csv(f\"ensmbl_{PRED_FILENAME}\", index=None)\n",
    "print(f\"saved submission file as ensmbl_{PRED_FILENAME}\")\n",
    "\n",
    "display(submission.head()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filename = \"ensmbl_5_2025-05-19-13-16-53-0.659.csv\"\n",
    "# submission.to_csv(filename, index=None)\n",
    "# display(submission.head()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @torch.no_grad()\n",
    "# def get_submission_from_summed_probas(eval_dataset, proba_accumulator, format_for_submission=False, k=5):\n",
    "#     # Final prediction dictionary\n",
    "#     final_predictions = {}\n",
    "    \n",
    "#     # For each observation, get top-5 from accumulated probabilities\n",
    "#     for fname, proba in proba_accumulator.items():\n",
    "#         top5 = torch.topk(proba, k=k)\n",
    "#         final_predictions[fname] = top5.indices.numpy()  # or top5.values if needed too\n",
    "    \n",
    "#     # Map predictions back to eval dataset\n",
    "#     eval_dataset.df[\"preds\"] = eval_dataset.df[\"observationID\"].map(final_predictions)\n",
    "    \n",
    "#     submission = eval_dataset.df.copy()\n",
    "#     submission = submission.drop_duplicates(subset=\"observationID\")\n",
    "    \n",
    "#     if format_for_submission:\n",
    "#         submission = submission[[\"observationID\", \"preds\"]]\n",
    "#         submission['preds'] = submission['preds'].apply(lambda x: ' '.join(map(str, x)))\n",
    "\n",
    "#     return submission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sanity checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_val_dataset.df.filename.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset.df.filename.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset.df.filename.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset.df.embedding[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset.df.transformation.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_val_dataset.df.transformation.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset.df.transformation.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset.df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset.df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(avg_embeddings_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset.df[\"observationID\"].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_10.indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 12156235,
     "sourceId": 91448,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30919,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "fungiclef2025",
   "language": "python",
   "name": "fungiclef2025"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
